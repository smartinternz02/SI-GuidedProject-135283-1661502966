{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UPD: 11.03.21**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import pandas_profiling as pdp\n",
    "\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import the necessary modelling algos.\n",
    "\n",
    "#classifiaction.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'stroke', y = 'smoking_status', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Unknown' and 'never smoker' has a low percentage of strokes in the sample. Let's combine them into one group: 'never smoker'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'Unknown': 'never smoked'}\n",
    "\n",
    "df = df.replace({'smoking_status': replace_values})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 2, figsize = (12, 20))\n",
    "sns.boxplot(x = 'avg_glucose_level', data = df, ax=axes[0][0])\n",
    "sns.boxplot(x = 'age', data = df, ax=axes[1][0])\n",
    "sns.boxplot(x = 'bmi', data = df, ax=axes[2][0])\n",
    "sns.boxplot(x = 'smoking_status', y = 'age', hue = 'stroke', data = df, ax=axes[3][0])\n",
    "sns.boxplot(x = 'hypertension',y = 'age', hue = 'stroke', data = df, ax=axes[3][1])\n",
    "sns.boxplot(x = 'heart_disease', y= 'age', hue = 'stroke', data = df, ax=axes[0][1])\n",
    "sns.boxplot(x = 'ever_married',y = 'age', hue = 'stroke', data = df, ax = axes[1][1])\n",
    "sns.boxplot(x = 'work_type',y = 'age',hue = 'stroke', data = df, ax = axes[2][1])\n",
    "sns.boxplot(x = 'Residence_type',y = 'age',hue = 'stroke', data = df, ax = axes[4][0])\n",
    "sns.boxplot(x = 'smoking_status',y = 'age', hue = 'stroke', data = df, ax = axes[4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good insights :)\n",
    "\n",
    "We have oultiers in avg_glucose_level and bmi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thanks for the function https://www.kaggle.com/ankitak46\n",
    "\n",
    "def remove_outliers(data):\n",
    "    arr=[]\n",
    "    #print(max(list(data)))\n",
    "    q1=np.percentile(data,25)\n",
    "    q3=np.percentile(data,75)\n",
    "    iqr=q3-q1\n",
    "    mi=q1-(1.5*iqr)\n",
    "    ma=q3+(1.5*iqr)\n",
    "    #print(mi,ma)\n",
    "    for i in list(data):\n",
    "        if i<mi:\n",
    "            i=mi\n",
    "            arr.append(i)\n",
    "        elif i>ma:\n",
    "            i=ma\n",
    "            arr.append(i)\n",
    "        else:\n",
    "            arr.append(i)\n",
    "    #print(max(arr))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi'] = remove_outliers(df['bmi'])\n",
    "df['avg_glucose_level'] = remove_outliers(df['avg_glucose_level'])\n",
    "print('Outliers successfully removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (10, 5))\n",
    "sns.boxplot(x = 'bmi', data = df, ax=axes[1][0])\n",
    "sns.boxplot(x = 'avg_glucose_level', data = df, ax=axes[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "df['ever_married'] = le.fit_transform(df['ever_married'])\n",
    "df = pd.get_dummies(df, columns = ['work_type'])\n",
    "df = pd.get_dummies(df, columns = ['Residence_type'])\n",
    "df = pd.get_dummies(df, columns = ['smoking_status'])\n",
    "df = df.drop('id', axis = 1)\n",
    "print('Encoding was successful ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('stroke', axis = 1)\n",
    "y = df.stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use sampling because there is an imbalance of the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### before oversampling\n",
    "\n",
    "sns.countplot(x = y, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y==0)))\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### after oversampling\n",
    "\n",
    "sns.countplot(x = y_res, data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "print(confusion_matrix(dtc_pred, y_test))\n",
    "print('-----')\n",
    "print(classification_report(dtc_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(confusion_matrix(rf_pred, y_test))\n",
    "print('-----')\n",
    "print(classification_report(rf_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's best F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "print(confusion_matrix(lr_pred, y_test))\n",
    "print('-----')\n",
    "print(classification_report(lr_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(svc_pred, y_test))\n",
    "print('-----')\n",
    "print(classification_report(svc_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(knn_pred, y_test))\n",
    "print('-----')\n",
    "print(classification_report(knn_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_valid_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13],\n",
    "}\n",
    "\n",
    "model_dtc = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "model_dtc = GridSearchCV(\n",
    "    model_dtc, \n",
    "    parameters, \n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "model_dtc.fit(X_train, y_train)\n",
    "model_dtc_pred = model_dtc.predict(X_test)\n",
    "print(classification_report(model_dtc_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_dtc.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \\\n",
    "    f'{model_dtc.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['desicion_tree'] = model_dtc.best_score_\n",
    "print('-----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 25], \n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13],\n",
    "}\n",
    "\n",
    "model_rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "model_rf = GridSearchCV(\n",
    "    model_rf, \n",
    "    parameters, \n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_rf_pred = model_rf.predict(X_test)\n",
    "print(classification_report(model_rf_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_rf.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n",
    "    f'{model_rf.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['random_forest'] = model_rf.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'max_depth': [3, 5, 7, 9], \n",
    "    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    random_state=42, verbosity = 0\n",
    ")\n",
    "\n",
    "model_xgb = GridSearchCV(\n",
    "    model_xgb, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "model_xgb_pred = model_xgb.predict(X_test)\n",
    "print(classification_report(model_xgb_pred, y_test))\n",
    "\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_xgb.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \n",
    "    f'{model_xgb.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['xgboost'] = model_xgb.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [7, 15, 31],\n",
    "}\n",
    "\n",
    "model_lgbm = lgbm.LGBMClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "model_lgbm = GridSearchCV(\n",
    "    model_lgbm, \n",
    "    parameters, \n",
    "    cv=5)\n",
    "\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "model_lgbm_pred = model_lgbm.predict(X_test)\n",
    "print(classification_report(model_lgbm_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_lgbm.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \n",
    "    f'{model_lgbm.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['lightgbm'] = model_lgbm.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 25, 50, 75, 100], \n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1.],\n",
    "}\n",
    "\n",
    "model_adaboost = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model_adaboost = GridSearchCV(\n",
    "    model_adaboost, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "model_adaboost_pred = model_adaboost.predict(X_test)\n",
    "print(classification_report(model_adaboost_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_adaboost.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n",
    "    f'{model_adaboost.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['ada_boost'] = model_adaboost.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.],\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    ")\n",
    "\n",
    "model_lr = GridSearchCV(\n",
    "    model_lr, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "model_lr_pred = model_lr.predict(X_test)\n",
    "print(classification_report(model_lr_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_lr.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \n",
    "    f'{model_lr.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['logistic_regression'] = model_lr.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "\n",
    "model_k_neighbors = KNeighborsClassifier(\n",
    ")\n",
    "\n",
    "model_k_neighbors = GridSearchCV(\n",
    "    model_k_neighbors, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "model_k_neighbors.fit(X_train, y_train)\n",
    "model_k_neighbors_pred = model_k_neighbors.predict(X_test)\n",
    "print(classification_report(model_k_neighbors_pred, y_test))\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_k_neighbors.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \n",
    "    f'{model_k_neighbors.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['k_neighbors'] = model_k_neighbors.best_score_\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank for watching!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you liked my work then upvoted or write your opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
